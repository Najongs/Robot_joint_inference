{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class RobotPoseDataset(Dataset):\n",
    "    def __init__(self, rgb_dir, depth_dir, angle_dir, transform=None):\n",
    "        super().__init__()\n",
    "        self.rgb_dir = rgb_dir\n",
    "        self.depth_dir = depth_dir\n",
    "        self.angle_dir = angle_dir\n",
    "        self.transform = transform\n",
    "        \n",
    "        self.samples = []\n",
    "        angle_file = [f for f in os.listdir(angle_dir) if f.endswith('.json')]\n",
    "        for i in range(len(angle_file)):\n",
    "            with open(os.path.join(angle_dir, angle_file[i]), 'r') as f:\n",
    "                data = json.load(f)\n",
    "                filename = angle_file[i].rstrip(\".json\")\n",
    "                self.samples.append((filename[5:], data))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # 1) (파일명, 관절각도 리스트) 가져오기\n",
    "        filename, angles = self.samples[idx]\n",
    "        \n",
    "        # 2) 실제 파일 경로\n",
    "        rgb_path = os.path.join(self.rgb_dir, f\"image{filename}.jpg\")\n",
    "        depth_path = os.path.join(self.depth_dir, f\"depth{filename}.jpg\")\n",
    "        \n",
    "        # 3) 이미지 불러오기 (PIL)\n",
    "        rgb_image = Image.open(rgb_path).convert(\"RGB\")  # (H,W,3)\n",
    "        depth_image = Image.open(depth_path).convert(\"L\")  # (H,W) grayscale\n",
    "        \n",
    "        # 4) numpy array로 변환 (0~1 스케일링 예시)\n",
    "        rgb_np = np.array(rgb_image, dtype=np.float32) / 255.0   # shape (H, W, 3)\n",
    "        depth_np = np.array(depth_image, dtype=np.float32) / 255.0  # shape (H, W)\n",
    "        \n",
    "        # 5) RGB + Depth 합치기 → shape (H, W, 4)\n",
    "        combined_np = np.dstack((rgb_np, depth_np))\n",
    "        \n",
    "        # 6) PyTorch 텐서 변환 (C, H, W) 순서로 바꿔주기\n",
    "        combined_np = combined_np.transpose(2, 0, 1)  # (4, H, W)\n",
    "        combined_tensor = torch.from_numpy(combined_np)  # float32 tensor\n",
    "        \n",
    "        # 7) 만약 추가 Transform이 있다면 적용 (예: Resize, Normalize 등)\n",
    "        #    (transform이 PIL 이미지를 요구한다면, 여기서 PIL -> Tensor 변환 위치를 조정해야 함)\n",
    "        if self.transform:\n",
    "            combined_tensor = self.transform(combined_tensor)\n",
    "\n",
    "        # 8) 관절 각도(라디안 or 도 단위)를 텐서로 변환\n",
    "        angles_tensor = torch.tensor(angles, dtype=torch.float32)\n",
    "        \n",
    "        return combined_tensor, angles_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RobotJointRegressor(nn.Module):\n",
    "    def __init__(self, input_channels=4, num_joints=6):\n",
    "        super(RobotJointRegressor, self).__init__()\n",
    "        \n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(input_channels, 8, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),   # 720x1280 -> 360x640\n",
    "\n",
    "            nn.Conv2d(8, 16, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),   # 360x640 -> 180x320\n",
    "\n",
    "            nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),   # 180x320 -> 90x160\n",
    "\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),   # 90x160 -> 45x80\n",
    "\n",
    "            nn.AdaptiveAvgPool2d((4, 4))   # 최종 (채널=64, 높이=4, 너비=4)\n",
    "        )\n",
    "        \n",
    "        # 최종 Feature map: (Batch, 64, 4, 4) → Flatten: 64*4*4=1024\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(64 * 4 * 4, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, num_joints)  # 6개의 관절 각도 회귀\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (Batch, 4, 720, 1280)\n",
    "        x = self.conv(x)              # (B, 64, 4, 4)\n",
    "        x = x.view(x.size(0), -1)     # Flatten (B, 1024)\n",
    "        x = self.fc(x)                # (B, 6)\n",
    "        return x\n",
    "\n",
    "\n",
    "def train_end_to_end(\n",
    "    dataloader,\n",
    "    num_epochs=50, \n",
    "    lr=1e-3, \n",
    "    device='cuda'\n",
    "):\n",
    "    model = RobotJointRegressor(input_channels=4, num_joints=6)\n",
    "    if device == 'cuda' and torch.cuda.device_count() > 1:\n",
    "        print(f\"Using {torch.cuda.device_count()} GPUs via nn.DataParallel...\")\n",
    "        model = nn.DataParallel(model)\n",
    "        \n",
    "    model.to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        total_batches = 0\n",
    "        \n",
    "        # dataloader로부터 (images, angles) 배치를 꺼냄\n",
    "        for batch_idx, (inputs, targets) in enumerate(dataloader):\n",
    "            inputs = inputs.to(device)   # (B, 4, H, W)\n",
    "            targets = targets.to(device) # (B, 6)\n",
    "\n",
    "            # Forward\n",
    "            preds = model(inputs)        # (B, 6)\n",
    "            loss = criterion(preds, targets)\n",
    "            \n",
    "            # Backprop + Update\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            total_batches += 1\n",
    "        \n",
    "        epoch_loss = running_loss / total_batches if total_batches > 0 else 0\n",
    "        print(f\"[Epoch {epoch+1}/{num_epochs}] Loss: {epoch_loss:.4f}\")\n",
    "    \n",
    "    return model\n",
    "\n",
    "# -----------------------------\n",
    "# 4) 실행 예시\n",
    "# -----------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    from torch.utils.data import DataLoader\n",
    "    \n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    rgb_dir = \"/home/najo/NAS/DIP/datasets/FR5_model/image\"\n",
    "    depth_dir = \"/home/najo/NAS/DIP/datasets/FR5_model/depth\"\n",
    "    angle_dir = \"/home/najo/NAS/DIP/datasets/FR5_model/angle\"\n",
    "\n",
    "    dataset = RobotPoseDataset(rgb_dir, depth_dir, angle_dir)\n",
    "    dataloader = DataLoader(dataset, batch_size=128, num_workers=16, shuffle=True, pin_memory=True)\n",
    "\n",
    "    for batch_idx, (images, angles) in enumerate(dataloader):\n",
    "        print(\"Batch:\", batch_idx)\n",
    "        print(\"images shape:\", images.shape)  # (B, 4, H, W)\n",
    "        print(\"angles shape:\", angles.shape)  # (B, 6)   (관절 6개 가정)\n",
    "        \n",
    "        break  # 데모로 한 번만 출력해보고 종료\n",
    "    \n",
    "    trained_model = train_end_to_end(dataloader, num_epochs=50, lr=1e-3, device=device)\n",
    "    print(\"Training Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 3 GPUs via nn.DataParallel...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1/50] Loss: 6013.4505\n",
      "[Epoch 2/50] Loss: 5218.6428\n",
      "[Epoch 3/50] Loss: 1760.5491\n",
      "[Epoch 4/50] Loss: 871.2631\n",
      "[Epoch 5/50] Loss: 783.6198\n",
      "[Epoch 6/50] Loss: 689.6333\n",
      "[Epoch 7/50] Loss: 665.4722\n",
      "[Epoch 8/50] Loss: 628.8259\n",
      "[Epoch 9/50] Loss: 620.0034\n",
      "[Epoch 10/50] Loss: 620.6606\n",
      "[Epoch 11/50] Loss: 619.1944\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 123\u001b[0m\n\u001b[1;32m    120\u001b[0m dataloader \u001b[38;5;241m=\u001b[39m DataLoader(dataset, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m128\u001b[39m, num_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, pin_memory\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    122\u001b[0m model \u001b[38;5;241m=\u001b[39m RobotJointRegressorMultiHead(input_channels\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m, num_joints\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m6\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m--> 123\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_multi_regression\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    124\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    125\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    126\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    127\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    128\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\n\u001b[1;32m    129\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining Done!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[5], line 93\u001b[0m, in \u001b[0;36mtrain_multi_regression\u001b[0;34m(model, dataloader, num_epochs, lr, device)\u001b[0m\n\u001b[1;32m     88\u001b[0m total_batches \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_idx, (images, angles) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(dataloader):\n\u001b[1;32m     91\u001b[0m     \u001b[38;5;66;03m# images: (B, 4, H, W)\u001b[39;00m\n\u001b[1;32m     92\u001b[0m     \u001b[38;5;66;03m# angles: (B, 6) -> 연속값 (회귀)\u001b[39;00m\n\u001b[0;32m---> 93\u001b[0m     images \u001b[38;5;241m=\u001b[39m \u001b[43mimages\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     94\u001b[0m     angles \u001b[38;5;241m=\u001b[39m angles\u001b[38;5;241m.\u001b[39mto(device)   \u001b[38;5;66;03m# float\u001b[39;00m\n\u001b[1;32m     96\u001b[0m     preds \u001b[38;5;241m=\u001b[39m model(images)        \u001b[38;5;66;03m# (B, 6)\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "class RobotJointRegressorMultiHead(nn.Module):\n",
    "    \"\"\"\n",
    "    - 공통 CNN으로 feature 추출\n",
    "    - 관절(조인트)마다 독립적인 회귀 head (스칼라 출력)\n",
    "    \"\"\"\n",
    "    def __init__(self, input_channels=4, num_joints=6):\n",
    "        super().__init__()\n",
    "        self.num_joints = num_joints\n",
    "        \n",
    "        # -----------------------\n",
    "        # 1) 공통 Convolution 백본\n",
    "        # -----------------------\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(input_channels, 8, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),   # 예: 720x1280 -> 360x640\n",
    "\n",
    "            nn.Conv2d(8, 16, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),   # 360x640 -> 180x320\n",
    "\n",
    "            nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),   # 180x320 -> 90x160\n",
    "\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),   # 90x160 -> 45x80\n",
    "\n",
    "            nn.AdaptiveAvgPool2d((4, 4))   # 최종 (B, 64, 4, 4)\n",
    "        )\n",
    "        \n",
    "        # -----------------------\n",
    "        # 2) 공통 Fully Connected (차원 축소)\n",
    "        # -----------------------\n",
    "        self.common_fc = nn.Sequential(\n",
    "            nn.Linear(64 * 4 * 4, 128),  # 64*4*4=1024\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        # -----------------------\n",
    "        # 3) 관절별 독립 Head\n",
    "        #    각 관절이 스칼라(회귀) 하나씩\n",
    "        # -----------------------\n",
    "        self.heads = nn.ModuleList([\n",
    "            nn.Linear(128, 1) for _ in range(num_joints)\n",
    "        ])\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x shape: (B, 4, H, W)\n",
    "        return: (B, 6)  # 6개 관절 회귀값\n",
    "        \"\"\"\n",
    "        feat = self.conv(x)              # (B, 64, 4, 4)\n",
    "        feat = feat.view(feat.size(0), -1)  # (B, 1024)\n",
    "        common_feat = self.common_fc(feat)  # (B, 128)\n",
    "        \n",
    "        # 관절별로 독립 예측\n",
    "        outputs = []\n",
    "        for head in self.heads:\n",
    "            out_joint = head(common_feat)  # (B, 1)\n",
    "            outputs.append(out_joint)\n",
    "        \n",
    "        # (B, 6) 형태로 합치기\n",
    "        # 각 관절별 (B,1)을 dim=1로 concat\n",
    "        outputs = torch.cat(outputs, dim=1)  # (B, 6)\n",
    "        return outputs\n",
    "\n",
    "def train_multi_regression(\n",
    "    model,\n",
    "    dataloader,\n",
    "    num_epochs=30,\n",
    "    lr=1e-3,\n",
    "    device='cuda'\n",
    "):\n",
    "    if device == 'cuda' and torch.cuda.device_count() > 1:\n",
    "        print(f\"Using {torch.cuda.device_count()} GPUs via nn.DataParallel...\")\n",
    "        model = nn.DataParallel(model)\n",
    "    \n",
    "    model.to(device)\n",
    "    \n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        total_batches = 0\n",
    "\n",
    "        for batch_idx, (images, angles) in enumerate(dataloader):\n",
    "            # images: (B, 4, H, W)\n",
    "            # angles: (B, 6) -> 연속값 (회귀)\n",
    "            images = images.to(device)\n",
    "            angles = angles.to(device)   # float\n",
    "            \n",
    "            preds = model(images)        # (B, 6)\n",
    "            loss = criterion(preds, angles)  # MSELoss for multi-output\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            total_batches += 1\n",
    "        \n",
    "        epoch_loss = running_loss / total_batches if total_batches > 0 else 0\n",
    "        print(f\"[Epoch {epoch+1}/{num_epochs}] Loss: {epoch_loss:.4f}\")\n",
    "    \n",
    "    return model\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    from torch.utils.data import DataLoader\n",
    "    \n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    rgb_dir = \"/home/najo/NAS/DIP/datasets/FR5_model/image\"\n",
    "    depth_dir = \"/home/najo/NAS/DIP/datasets/FR5_model/depth\"\n",
    "    angle_dir = \"/home/najo/NAS/DIP/datasets/FR5_model/angle\"\n",
    "\n",
    "    dataset = RobotPoseDataset(rgb_dir, depth_dir, angle_dir)\n",
    "    dataloader = DataLoader(dataset, batch_size=128, num_workers=16, shuffle=True, pin_memory=True)\n",
    "\n",
    "    model = RobotJointRegressorMultiHead(input_channels=4, num_joints=6).to(device)\n",
    "    model = train_multi_regression(\n",
    "        model=model,\n",
    "        dataloader=dataloader,\n",
    "        num_epochs=50,\n",
    "        lr=1e-3,\n",
    "        device=device\n",
    "    )\n",
    "    \n",
    "    print(\"Training Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dip",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
